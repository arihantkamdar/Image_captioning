# Image_captioning
##A image Captioning project based in Deep learning using Flickr_8k dataset.


The Dataset of Flickr_8k can we downloaded from [kaggle](:https://www.kaggle.com/adityajn105/flickr8k)

See the demo of captions generated using the model


![image1](https://drive.google.com/file/d/1AeiDfyHHl000KjIShqCo6lfV4YunpFo_/view?usp=sharing)

Caption: start dog runs through the water end

![image2](https://drive.google.com/file/d/14AWldWDwKnXzGLGAX8jX8UiFcddYGyHG/view?usp=sharing)

Caption: start man in blue shirt and jeans is riding bicycle on the street end

![image3](https://drive.google.com/file/d/1jHx-XlKFFH_I4Hbn_iq4F1DSjbxdlsSp/view?usp=sharing)
start boy is playing softball end



#How to use the repository

1. Download the dataset and open image_captioning.ipynb
2. Unzip the dataset and set the directories in the python notebook
3. Make the deep learning by running Image_captioning.ipynb and a models would be saved in a directory named model
4. Now open driver_code_of_image_captioning.ipynb and set the directories of the files required i.e: tokenizer.p, features.p, model_9.h5 and description.txt
5. Set the path of an image for which caption should be generated, here we used images from Images folder
6. Run driver_code_of_image_captioning.ipynb
