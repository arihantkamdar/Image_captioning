# Image_captioning
##A image Captioning project based in Deep learning using Flickr_8k dataset.


The Dataset of Flickr_8k can we downloaded from [kaggle](:https://www.kaggle.com/adityajn105/flickr8k)

See the demo of captions generated using the model


![image1](/images/beach.jpg)
Caption: start dog runs through the water end

![image2](/images/child.png)
Caption: start man in blue shirt and jeans is riding bicycle on the street end

![image3](/image/image.jpg)
start boy is playing softball end



#How to use the repository

1. Download the dataset and open image_captioning.ipynb
2. Unzip the dataset and set the directories in the python notebook
3. Make the deep learning by running Image_captioning.ipynb and a models would be saved in a directory named model
4. Now open driver_code_of_image_captioning.ipynb and set the directories of the files required i.e: tokenizer.p, features.p, model_9.h5 and description.txt
5. Set the path of an image for which caption should be generated, here we used images from Images folder
6. Run driver_code_of_image_captioning.ipynb
