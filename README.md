# Image_captioning
## A image Captioning project based in Deep learning using Flickr_8k dataset.


The Dataset of Flickr_8k can we downloaded from [kaggle](:https://www.kaggle.com/adityajn105/flickr8k)

See the demo of captions generated using the model


![image1](https://github.com/arihantkamdar/Image_captioning/tree/main/Images/beach.jpg)

Caption: start dog runs through the water end

![image2](https://github.com/arihantkamdar/Image_captioning/tree/main/Images/child.png)

Caption: start man in blue shirt and jeans is riding bicycle on the street end

![image3](https://github.com/arihantkamdar/Image_captioning/tree/main/Images/image/jpg)

Caption: start boy is playing softball end



# How to use the repository

1. Download the dataset and open image_captioning.ipynb
2. Unzip the dataset and set the directories in the python notebook
3. Make the deep learning by running Image_captioning.ipynb and a models would be saved in a directory named model
4. Now open driver_code_of_image_captioning.ipynb and set the directories of the files required i.e: tokenizer.p, features.p, model_9.h5 and description.txt
5. Set the path of an image for which caption should be generated, here we used images from Images folder
6. Run driver_code_of_image_captioning.ipynb
